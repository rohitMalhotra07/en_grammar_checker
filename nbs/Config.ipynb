{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Config file\n",
    "\n",
    "> set dataset path, model_name, validation split, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "\n",
    "class Config:\n",
    "    \"Class to define config for the project\"\n",
    "    seed = 42\n",
    "    base_dataset_path = \"../data/cola_public/raw/\"\n",
    "    base_model_name = \"microsoft/deberta-v3-large\"\n",
    "\n",
    "    trained_model_path = \"../trained_models/en_grammar_checker1.pt\"\n",
    "\n",
    "    train_path = f\"{base_dataset_path}in_domain_train.tsv\"\n",
    "\n",
    "    train_val_split = 0.15\n",
    "    num_workers = 4\n",
    "\n",
    "    # Model Params\n",
    "    context_length = 512  # Maximum sentence length\n",
    "    num_classes = 2\n",
    "\n",
    "    # Training Params\n",
    "    training_logs_path = \"../training_logs\"\n",
    "    experiment_name = \"test_run1\"\n",
    "\n",
    "    train_batch_size = 32\n",
    "    val_batch_size = 32\n",
    "    test_batch_size = 1\n",
    "    num_epochs = 50\n",
    "    early_stopping_rounds = 7\n",
    "    # learning_rate = 2e-5\n",
    "    # learning_rate = 0.0002051162178825565\n",
    "    learning_rate = 2e-4\n",
    "    eps = 1e-8\n",
    "    weight_decay = 0.01\n",
    "    betas = (0.9, 0.999)\n",
    "    warmup_prop = 0.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
