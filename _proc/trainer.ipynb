{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62336e59-6329-4975-ad9b-27bf76153cb6",
   "metadata": {},
   "source": [
    "## PL Trainer for training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90484fda-45cb-46b9-ab76-3feb59d6a689",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: \"Exported source\"\n",
    "import lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from en_grammar_checker.models import EnDeBertaClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186a202c-2912-4ff9-9bbf-7f2eadd5c53d",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from en_grammar_checker.config import Config\n",
    "from en_grammar_checker.datasets import get_train_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rohitMalhotra07/en_grammar_checker/blob/main/en_grammar_checker/trainer.py#L20){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MyLightningClassifierModel\n",
       "\n",
       ">      MyLightningClassifierModel (cnfg)\n",
       "\n",
       "*Hooks to be used in LightningModule.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rohitMalhotra07/en_grammar_checker/blob/main/en_grammar_checker/trainer.py#L20){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MyLightningClassifierModel\n",
       "\n",
       ">      MyLightningClassifierModel (cnfg)\n",
       "\n",
       "*Hooks to be used in LightningModule.*"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(MyLightningClassifierModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb1fe90-926c-41c1-a04b-d01cf1d8de67",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: \"Exported source\"\n",
    "# define the LightningModule\n",
    "class MyLightningClassifierModel(pl.LightningModule):\n",
    "    def __init__(self, cnfg):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = EnDeBertaClassifier(cnfg)\n",
    "\n",
    "        self.learning_rate = cnfg.learning_rate\n",
    "        self.eps = cnfg.eps\n",
    "        self.weight_decay = cnfg.weight_decay\n",
    "        self.betas = cnfg.betas\n",
    "        self.warmup_prop = cnfg.warmup_prop\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x, x2, y = batch\n",
    "        # y = y.view(-1)\n",
    "        pred = self.model(input_ids=x, attention_mask=x2)\n",
    "        loss = loss_fct(pred, y)\n",
    "\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log(\n",
    "            \"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, pred, y, _f1, _precision, _recall = self._shared_eval_step(\n",
    "            batch, batch_idx\n",
    "        )\n",
    "        # metrics = {\n",
    "        #     \"val_loss\": loss,\n",
    "        #     \"val_f1\": _f1,\n",
    "        #     \"val_precision\": _precision,\n",
    "        #     \"val_recall\": _recall,\n",
    "        # }\n",
    "        self.log(\n",
    "            \"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "\n",
    "        self.log(\n",
    "            \"val_f1\", _f1, on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "\n",
    "        self.log(\n",
    "            \"val_precision\",\n",
    "            _precision,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "        )\n",
    "\n",
    "        self.log(\n",
    "            \"val_recall\",\n",
    "            _recall,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "        )\n",
    "\n",
    "        self.validation_step_y_hat.append(pred)\n",
    "        self.validation_step_y.append(y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_start(self):\n",
    "        self.validation_step_y_hat = []  # free memory\n",
    "        self.validation_step_y = []\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        all_preds = torch.cat(self.validation_step_y_hat)\n",
    "        all_y = torch.cat(self.validation_step_y)\n",
    "\n",
    "        all_preds = torch.argmax(all_preds, axis=1).flatten().detach().cpu()\n",
    "        all_y = all_y.flatten().detach().cpu()\n",
    "\n",
    "        # do something with all preds\n",
    "        _f1 = f1_score(all_preds, all_y, average=\"macro\")\n",
    "        _precision = precision_score(all_preds, all_y, average=\"macro\")\n",
    "        _recall = recall_score(all_preds, all_y, average=\"macro\")\n",
    "        # metrics = {\n",
    "        #     \"val_f1_full\": _f1,\n",
    "        #     \"val_precision_full\": _precision,\n",
    "        #     \"val_recall_full\": _recall,\n",
    "        # }\n",
    "        # self.log_dict(metrics)\n",
    "\n",
    "        print(\n",
    "            f\"\\t Epoch: {self.current_epoch}, Val F1: {_f1}, Val Precision: {_precision}, Val Recall {_recall}\"\n",
    "        )\n",
    "\n",
    "    def _shared_eval_step(self, batch, batch_idx):\n",
    "        x, x2, y = batch\n",
    "        # y = y.reshape(-1, 1)\n",
    "        pred = self.model(input_ids=x, attention_mask=x2)\n",
    "        loss = loss_fct(pred, y)\n",
    "\n",
    "        _f1 = f1_score(\n",
    "            torch.argmax(pred, axis=1).cpu().numpy(), y.cpu().numpy(), average=\"macro\"\n",
    "        )\n",
    "        _precision = precision_score(\n",
    "            torch.argmax(pred, axis=1).cpu().numpy(), y.cpu().numpy(), average=\"macro\"\n",
    "        )\n",
    "\n",
    "        _recall = recall_score(\n",
    "            torch.argmax(pred, axis=1).cpu().numpy(), y.cpu().numpy(), average=\"macro\"\n",
    "        )\n",
    "        return loss, pred, y, _f1, _precision, _recall\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        x, x2 = batch\n",
    "        pred = self.model(x)\n",
    "        return pred\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # return optimizer\n",
    "        optimizer = AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=self.learning_rate,\n",
    "            eps=self.eps,\n",
    "            weight_decay=self.weight_decay,\n",
    "            betas=self.betas,\n",
    "        )\n",
    "        # get_linear_schedule_with_warmup(\n",
    "        #     optimizer,\n",
    "        #     num_warmup_steps=len(self.train_dataloader)\n",
    "        #     * self.num_epochs\n",
    "        #     * self.warmup_prop,\n",
    "        #     num_training_steps=len(self.train_dataloader) * self.num_epochs,\n",
    "        # )\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            patience=5,\n",
    "            factor=0.1,\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": scheduler,\n",
    "            \"monitor\": \"train_loss\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358a344a-5654-46ea-9cff-54b0f8e60ae3",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
