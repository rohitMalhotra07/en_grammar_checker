{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: datasets.html\n",
    "title: Classes for data preparation and creating datasets\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ea487d-0d53-4e70-8382-4900016f7b6d",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: \"Exported source\"\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51824f3c-46e7-4460-aca4-45bdec015ca6",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from en_grammar_checker.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9038fb5-ed8a-48b4-961f-7ec2f305b52b",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rohitMalhotra07/en_grammar_checker/blob/main/en_grammar_checker/datasets.py#L17){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BertClassificationDataset\n",
       "\n",
       ">      BertClassificationDataset (cnfg, df:pandas.core.frame.DataFrame,\n",
       ">                                 is_test:bool=False, input_clm:str='sentence',\n",
       ">                                 label_clm:str='label')\n",
       "\n",
       "*An abstract class representing a :class:`Dataset`.\n",
       "\n",
       "All datasets that represent a map from keys to data samples should subclass\n",
       "it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
       "data sample for a given key. Subclasses could also optionally overwrite\n",
       ":meth:`__len__`, which is expected to return the size of the dataset by many\n",
       ":class:`~torch.utils.data.Sampler` implementations and the default options\n",
       "of :class:`~torch.utils.data.DataLoader`. Subclasses could also\n",
       "optionally implement :meth:`__getitems__`, for speedup batched samples\n",
       "loading. This method accepts list of indices of samples of batch and returns\n",
       "list of samples.\n",
       "\n",
       ".. note::\n",
       "  :class:`~torch.utils.data.DataLoader` by default constructs an index\n",
       "  sampler that yields integral indices.  To make it work with a map-style\n",
       "  dataset with non-integral indices/keys, a custom sampler must be provided.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rohitMalhotra07/en_grammar_checker/blob/main/en_grammar_checker/datasets.py#L17){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BertClassificationDataset\n",
       "\n",
       ">      BertClassificationDataset (cnfg, df:pandas.core.frame.DataFrame,\n",
       ">                                 is_test:bool=False, input_clm:str='sentence',\n",
       ">                                 label_clm:str='label')\n",
       "\n",
       "*An abstract class representing a :class:`Dataset`.\n",
       "\n",
       "All datasets that represent a map from keys to data samples should subclass\n",
       "it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
       "data sample for a given key. Subclasses could also optionally overwrite\n",
       ":meth:`__len__`, which is expected to return the size of the dataset by many\n",
       ":class:`~torch.utils.data.Sampler` implementations and the default options\n",
       "of :class:`~torch.utils.data.DataLoader`. Subclasses could also\n",
       "optionally implement :meth:`__getitems__`, for speedup batched samples\n",
       "loading. This method accepts list of indices of samples of batch and returns\n",
       "list of samples.\n",
       "\n",
       ".. note::\n",
       "  :class:`~torch.utils.data.DataLoader` by default constructs an index\n",
       "  sampler that yields integral indices.  To make it work with a map-style\n",
       "  dataset with non-integral indices/keys, a custom sampler must be provided.*"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(BertClassificationDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17b75ba-cb11-42e4-8f03-f82177515b99",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: \"Exported source\"\n",
    "class BertClassificationDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cnfg,\n",
    "        df: pd.DataFrame,\n",
    "        is_test: bool = False,\n",
    "        input_clm: str = \"sentence\",\n",
    "        label_clm: str = \"label\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        cnfg: instance of Config class\n",
    "        df: dataframe of data with label\n",
    "        is_test: True if it for inference dataframe\n",
    "        input_clm: column name for sentences\n",
    "        label_clm: column name for label (dtype should not be object)\n",
    "        \"\"\"\n",
    "        # get tokenizer from model name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(cnfg.base_model_name)\n",
    "        self.df = df\n",
    "        self.is_test = is_test\n",
    "        self.cnfg = cnfg\n",
    "        self.input_clm = input_clm\n",
    "        self.label_clm = label_clm\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        row_tensors = []\n",
    "\n",
    "        encoded_dict = self.tokenizer.encode_plus(\n",
    "            row[self.input_clm],  # Sentence to encode.\n",
    "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "            max_length=self.cnfg.context_length,  # Pad & truncate all sentences.\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,  # Construct attn. masks.\n",
    "            return_tensors=\"pt\",  # Return pytorch tensors.\n",
    "        )\n",
    "\n",
    "        if self.is_test:\n",
    "            return (\n",
    "                encoded_dict[\"input_ids\"].squeeze(),\n",
    "                encoded_dict[\"attention_mask\"].squeeze(),\n",
    "            )\n",
    "        else:\n",
    "            label = torch.as_tensor(row[self.label_clm], dtype=torch.int64)\n",
    "            return (\n",
    "                encoded_dict[\"input_ids\"].squeeze(),\n",
    "                encoded_dict[\"attention_mask\"].squeeze(),\n",
    "                label,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rohitMalhotra07/en_grammar_checker/blob/main/en_grammar_checker/datasets.py#L72){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_train_data_loader\n",
       "\n",
       ">      get_train_data_loader (cnfg, df, input_clm:str='sentence',\n",
       ">                             label_clm:str='label')"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rohitMalhotra07/en_grammar_checker/blob/main/en_grammar_checker/datasets.py#L72){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_train_data_loader\n",
       "\n",
       ">      get_train_data_loader (cnfg, df, input_clm:str='sentence',\n",
       ">                             label_clm:str='label')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(get_train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25b1231-8343-488d-8d98-9d310fb19b17",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: \"Exported source\"\n",
    "def get_train_data_loader(\n",
    "    cnfg,\n",
    "    df,\n",
    "    input_clm: str = \"sentence\",\n",
    "    label_clm: str = \"label\",\n",
    "):\n",
    "    dataset = BertClassificationDataset(\n",
    "        cnfg, df, is_test=False, input_clm=input_clm, label_clm=label_clm\n",
    "    )\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        sampler=RandomSampler(dataset),  # Select batches randomly\n",
    "        batch_size=cnfg.train_batch_size,\n",
    "        num_workers=cnfg.num_workers,\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rohitMalhotra07/en_grammar_checker/blob/main/en_grammar_checker/datasets.py#L91){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_val_data_loader\n",
       "\n",
       ">      get_val_data_loader (cnfg, df, input_clm:str='sentence',\n",
       ">                           label_clm:str='label')"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rohitMalhotra07/en_grammar_checker/blob/main/en_grammar_checker/datasets.py#L91){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_val_data_loader\n",
       "\n",
       ">      get_val_data_loader (cnfg, df, input_clm:str='sentence',\n",
       ">                           label_clm:str='label')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(get_val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eeb6d8-2649-4f6d-8678-9996de47b06c",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: \"Exported source\"\n",
    "def get_val_data_loader(\n",
    "    cnfg,\n",
    "    df,\n",
    "    input_clm: str = \"sentence\",\n",
    "    label_clm: str = \"label\",\n",
    "):\n",
    "    dataset = BertClassificationDataset(\n",
    "        cnfg, df, is_test=False, input_clm=input_clm, label_clm=label_clm\n",
    "    )\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        sampler=SequentialSampler(dataset),  # Select batches sequentialy\n",
    "        batch_size=cnfg.val_batch_size,\n",
    "        num_workers=cnfg.num_workers,\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rohitMalhotra07/en_grammar_checker/blob/main/en_grammar_checker/datasets.py#L110){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_test_data_loader\n",
       "\n",
       ">      get_test_data_loader (cnfg, df, input_clm:str='sentence', label_clm=None)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rohitMalhotra07/en_grammar_checker/blob/main/en_grammar_checker/datasets.py#L110){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_test_data_loader\n",
       "\n",
       ">      get_test_data_loader (cnfg, df, input_clm:str='sentence', label_clm=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(get_test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82780eae-4cc4-42a9-8470-2c36b4fa8ac3",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: \"Exported source\"\n",
    "def get_test_data_loader(\n",
    "    cnfg,\n",
    "    df,\n",
    "    input_clm: str = \"sentence\",\n",
    "    label_clm=None,\n",
    "):\n",
    "    dataset = BertClassificationDataset(\n",
    "        cnfg, df, is_test=True, input_clm=input_clm, label_clm=label_clm\n",
    "    )\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        sampler=SequentialSampler(dataset),  # Select batches sequentialy\n",
    "        batch_size=cnfg.test_batch_size,\n",
    "        num_workers=cnfg.num_workers,\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9426fae-0bf6-4c90-9fed-3e2eccd0f64f",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6ea0d7a-2476-47de-aaee-542fe7b46471",
   "metadata": {},
   "source": [
    "### Testing DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905003ff-e819-4ab5-8af3-b795a36f0f04",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "cnfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbfea46-12fb-4202-b7f5-89e659e6ad56",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\n",
    "    f\"{cnfg.train_path}\",\n",
    "    delimiter=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"sentence_source\", \"label\", \"label_notes\", \"sentence\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fdab50-b242-424c-9363-7d97f93ff8fb",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee9f7d1-6e18-4121-b77e-6b97e6f09b84",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohit/Desktop/rohit/virtualenvs/rohit_transformers/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rohit/Desktop/rohit/virtualenvs/rohit_transformers/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = get_train_data_loader(cnfg, df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ef243a-e59e-4a3f-97ac-500e86765272",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/rohit/Desktop/rohit/virtualenvs/rohit_transformers/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2674: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataloader_iterator = iter(train_dataloader)\n",
    "X, X2, Y = next(train_dataloader_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23221d3-ada3-4522-8b47-93da73cf7292",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 512]), torch.Size([8, 512]), torch.Size([8]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X2.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a185cb1a-8425-4089-96e2-dcd4fc181765",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45648c19-58a3-4e03-864a-ef09e472e91a",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1,  585, 1234,  ...,    0,    0,    0],\n",
       "        [   1,  273,  481,  ...,    0,    0,    0],\n",
       "        [   1,  512,  313,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [   1,  273, 1659,  ...,    0,    0,    0],\n",
       "        [   1,  918, 3721,  ...,    0,    0,    0],\n",
       "        [   1, 1887,  261,  ...,    0,    0,    0]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6013ed96-30a4-4072-93a4-f2fad7b47f6c",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505abea5-c993-4f12-83ea-98bb14cda37c",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
